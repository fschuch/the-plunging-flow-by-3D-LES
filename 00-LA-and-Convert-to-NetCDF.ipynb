{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if incompact3d is configured with doubleprec then use np.float64\n",
    "myfloat = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [2, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = {0: \"Streamwise\", 1: \"Vertical\", 2: \"Spanwise\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prm_to_dict(path):\n",
    "    '''\n",
    "    This function reads the file BC-Plumes.prm from i3d and converts it into a Python dictionary\n",
    "    \n",
    "    Args:\n",
    "        path: Path to folder that contains the file BC-Plumes.prm\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary containing flow parameters\n",
    "    '''\n",
    "    prm = {}\n",
    "    prm[\"filename\"] = path + '/BC-Plumes.prm'\n",
    "    prm[\"datapath\"] = path + '/data/'  # <- default value\n",
    "    prm[\"x0ramp\"] = 0.0  # <- default value\n",
    "    f = open(prm[\"filename\"], 'r')\n",
    "    for line in f:\n",
    "        line = line.partition('#')[0]  #Remove comments\n",
    "        line = \" \".join(line.split())  #Remove white spaces\n",
    "        if line == '':  #Cycle if line is empty\n",
    "            continue\n",
    "\n",
    "        param = line.partition(' ')[0]\n",
    "        value = line.partition(param + ' ')[-1]\n",
    "        if value[0] == \"'\" and value[-1] == \"'\":  #String\n",
    "            value = value[1:-1]\n",
    "        elif \" \" in value:  #Array\n",
    "            if \".\" in value:\n",
    "                value = [float(i) for i in value.split(\" \")] #Float\n",
    "            else:\n",
    "                value = [int(i) for i in value.split(\" \")] #int\n",
    "        else:  #Not Array\n",
    "            if \".\" in value:\n",
    "                value = float(value) #Float\n",
    "            else:\n",
    "                value = int(value) #int\n",
    "        prm[param] = value\n",
    "    f.close()\n",
    "    return prm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x3d_readfield_2d(filename, n1, n2, n3=0, dtype=myfloat):\n",
    "    '''\n",
    "    This functions reads a binary field and returns it in a 2D numpy array, if\n",
    "    n3 is not zero, it computes a spanwise-average and returns a 2D numpy array.\n",
    "    \n",
    "    Args:\n",
    "        filename: File name.\n",
    "        n1: Number of points in axis 0.\n",
    "        n2: Number of points in axis 1.\n",
    "        n3: Number of points in axis 2.\n",
    "        dtype: Data type for Numpy array.\n",
    "    \n",
    "    Returns:\n",
    "        A Numpy array with shape (n1, n2)\n",
    "    \n",
    "    Example:\n",
    "        x3d_readfield_2d('./data/ux0010', 256, 64)\n",
    "        x3d_readfield_2d('./data/phi10010', 256, 64, 16)\n",
    "    '''\n",
    "    if n3 == 0:  #2D\n",
    "        return np.fromfile(filename, dtype=dtype).reshape((n1, n2),\n",
    "                                                                 order='F')\n",
    "    else:  #3D\n",
    "        return np.average(np.fromfile(filename, dtype=dtype).reshape(\n",
    "            (n1, n2, n3), order='F'),\n",
    "                          axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x3d_readfield_all_2d(target, n1, n2, n3=0, dtype=myfloat, engine='numpy'):\n",
    "    '''\n",
    "    This functions reads many binary fields and returns them in a stacked 3D array, if\n",
    "    n3 is not zero, it computes a spanwise average and returns a 3D dask array.\n",
    "    \n",
    "    Args:\n",
    "        Target: Pathname pattern.\n",
    "        n1: Number of points in axis 0.\n",
    "        n2: Number of points in axis 1.\n",
    "        n3: Number of points in axis 2.\n",
    "        dtype: Data type.\n",
    "        engine: 'numpy' or 'dask'\n",
    "    \n",
    "    Returns:\n",
    "        A array of shape (n1, n2, nfiles)\n",
    "    \n",
    "    Example:\n",
    "        x3d_readfield_all_2d('./data/ux*', 256, 64)\n",
    "        x3d_readfield_all_2d('./data/uy????', 256, 64, 16)\n",
    "    '''\n",
    "    #\n",
    "    filenames = sorted(glob.glob(target))\n",
    "    #\n",
    "    if engine.lower() == 'dask':\n",
    "\n",
    "        readfield = dask.delayed(x3d_readfield_2d, pure=True)\n",
    "\n",
    "        lazy_fields = [\n",
    "            readfield(file, n1, n2, n3, dtype=dtype) for file in filenames\n",
    "        ]\n",
    "\n",
    "        fields = [\n",
    "            da.from_delayed(lazy_field, dtype=myfloat, shape=(n1, n2))\n",
    "            for lazy_field in lazy_fields\n",
    "        ]\n",
    "\n",
    "        return da.stack(fields, axis=2)\n",
    "    elif engine.lower() == 'numpy':\n",
    "        fields = [\n",
    "            x3d_readfield_2d(file, n1, n2, n3, dtype=dtype)\n",
    "            for file in tqdm(filenames,\n",
    "                             desc=f'Reading {os.path.split(target)[-1]}')\n",
    "        ]\n",
    "\n",
    "        return np.dstack(fields)\n",
    "    else:\n",
    "        print('invalid value for engine')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x3d_readfield_3d(filename, n1, n2, n3, dtype=myfloat):\n",
    "    '''\n",
    "    This functions reads a binary field and returns it in a 3D numpy array.\n",
    "    \n",
    "    Args:\n",
    "        filename: File name.\n",
    "        n1: Number of points in axis 0.\n",
    "        n2: Number of points in axis 1.\n",
    "        n3: Number of points in axis 2.\n",
    "        dtype: Data type for Numpy array.\n",
    "    \n",
    "    Returns:\n",
    "        A Numpy array with shape (n1, n2, n3)\n",
    "    \n",
    "    Example:\n",
    "        x3d_readfield_2d('./data/ux0010', 256, 64, 16)\n",
    "        x3d_readfield_2d('./data/phi10010', 256, 64, 16)\n",
    "    '''\n",
    "    return np.fromfile(filename, dtype=dtype).reshape((n1, n2, n3),\n",
    "                                                                 order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dataset(prm):\n",
    "    '''\n",
    "    This function initializes a xarray.dataset with the proper size and\n",
    "    dimensions, in addition to some parameters and attributes.\n",
    "    \n",
    "    Args:\n",
    "        prm: A dictionary containing flow parameters\n",
    "    \n",
    "    Returns:\n",
    "        A xarray.Dataset\n",
    "    '''\n",
    "    ds = xr.Dataset(\n",
    "        coords={\n",
    "            'x':\n",
    "                np.linspace(\n",
    "                    0., prm[\"xlx\"], num=prm[\"nx\"], endpoint=True, dtype=myfloat)\n",
    "                - prm[\"x0ramp\"],\n",
    "            'y':\n",
    "                np.linspace(prm[\"yly\"],\n",
    "                            0.,\n",
    "                            num=prm[\"ny\"],\n",
    "                            endpoint=True,\n",
    "                            dtype=myfloat),\n",
    "            'z':\n",
    "                np.linspace(0.,\n",
    "                            prm[\"zlz\"],\n",
    "                            num=prm[\"nz\"],\n",
    "                            endpoint=False,\n",
    "                            dtype=myfloat),\n",
    "            't':\n",
    "                np.arange(\n",
    "                    0, prm[\"ilast\"] + 1, step=prm[\"iprocessing\"], dtype=myfloat)\n",
    "                * prm[\"dt\"],\n",
    "            'n':\n",
    "                range(prm[\"nphi\"])\n",
    "        },\n",
    "        attrs={\n",
    "            'title':\n",
    "                'The Plunging of Hyperpycnal Plumes on Tilted Bed by Three-Dimensional Large-Eddy Simulations',\n",
    "            'authors': 'F. N. Schuch, J. H. Silvestrini, E. Meiburg & S. Laizet',\n",
    "            'url': 'https://github.com/fschuch/the-plunging-flow-by-3D-LES',\n",
    "            'doi': '10.5281/zenodo.3968993'\n",
    "        })\n",
    "\n",
    "    ds.x.attrs = {'name': 'Streamwise coordinate', 'long_name': r'$x_1$'}\n",
    "    ds.y.attrs = {'name': 'Vertical coordinate', 'long_name': r'$x_2$'}\n",
    "    ds.z.attrs = {'name': 'Spanwise coordinate', 'long_name': r'$x_3$'}\n",
    "    ds.t.attrs = {'name': 'Time', 'long_name': r'$t$'}\n",
    "    ds.n.attrs = {'name': 'Scalar fraction', 'long_name': r'$\\ell$'}\n",
    "\n",
    "    ds['uset'] = xr.DataArray(prm['uset'][:prm['nphi']],\n",
    "                              dims=['n'],\n",
    "                              coords=[ds.n],\n",
    "                              attrs={\n",
    "                                  'name': 'Settling Velocity',\n",
    "                                  'long_name': r'$u_s$'\n",
    "                              })\n",
    "\n",
    "    ds['Ri0'] = xr.DataArray(prm['ri'][:prm['nphi']],\n",
    "                             dims=['n'],\n",
    "                             coords=[ds.n],\n",
    "                             attrs={\n",
    "                                 'name': 'Initial Richardson Number',\n",
    "                                 'long_name': r'$Ri_0$'\n",
    "                             })\n",
    "\n",
    "    ds['Fr0'] = xr.DataArray(ds.Ri0**(-0.5),\n",
    "                             dims=['n'],\n",
    "                             coords=[ds.n],\n",
    "                             attrs={\n",
    "                                 'name': 'Initial densimetric Froude Number',\n",
    "                                 'long_name': r'$Fr_0$'\n",
    "                             })\n",
    "\n",
    "    ds['Sc'] = xr.DataArray(prm['nsc'][:prm['nphi']],\n",
    "                            dims=['n'],\n",
    "                            coords=[ds.n],\n",
    "                            attrs={\n",
    "                                'name': 'Schmidt Number',\n",
    "                                'long_name': r'$Sc$'\n",
    "                            })\n",
    "\n",
    "    ds['Re'] = xr.DataArray(prm['re'],\n",
    "                            attrs={\n",
    "                                'name': 'Reynolds Number',\n",
    "                                'long_name': r'$Re$'\n",
    "                            })\n",
    "    '''\n",
    "    Defining the position of the tilded bed, some operations are necessary in order\n",
    "    to be consistent with the new coordinate system\n",
    "    '''\n",
    "\n",
    "    prm['xlx_pi'] -= prm['x0ramp']\n",
    "    prm['xlx_pf'] -= prm['x0ramp']\n",
    "\n",
    "    if 'declramp' in prm.keys():\n",
    "        ds['S'] = xr.DataArray(prm['declramp'],\n",
    "                               attrs={\n",
    "                                   'name': 'Bed slope',\n",
    "                                   'long_name': r'$S$'\n",
    "                               })\n",
    "\n",
    "        y0ramp = 1.\n",
    "        layer = prm['yly'] - prm['layer']\n",
    "\n",
    "        ramp = 1. + prm['declramp'] * ds.x\n",
    "\n",
    "        ramp[ramp < y0ramp] = y0ramp\n",
    "        ramp[ramp > layer] = layer\n",
    "\n",
    "        ds['ramp'] = ramp\n",
    "\n",
    "        ds.ramp.attrs['name'] = 'Bed position'\n",
    "        ds.ramp.attrs['long_name'] = '$x_{2r}$'\n",
    "\n",
    "        del ramp\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer-averaged quantities\n",
    "\n",
    "The complete spatio-temporal analysis of the relevant quantities is possible in a layer averaged context per width unit, that is computed according to the equations\n",
    "\n",
    "$$\n",
    "Uh(x_1,t) = \\dfrac{1}{L_3} \\int_0^{L_3} \\int_{x_{2r}}^{x_{2i}} u_1(x_1,x_2,x_3,t) ~ dx_2 dx_3\n",
    "$$\n",
    "$$\n",
    "U^2h(x_1,t) = \\dfrac{1}{L_3} \\int_0^{L_3} \\int_{x_{2r}}^{x_{2i}} \\big( u_1(x_1,x_2,x_3,t) \\big)^2 ~ dx_2 dx_3\n",
    "$$\n",
    "$$\n",
    "UCh(x_1,t) = \\dfrac{1}{L_3} \\int_0^{L_3} \\int_{x_{2r}}^{x_{2i}} u_1 (x_1,x_2,x_3,t) ~ c_t (x_1,x_2,x_3,t) ~ dx_2 dx_3\n",
    "$$\n",
    "\n",
    "For the vertical integration, $x_{2r}$ represents the bed position and $x_{2i}$ represents the interface between the underflow turbidity current and the ambient fluid, considered in this work as the position where $u_1 c_t = 0.005$.\n",
    "Then, they can be used to compute layer-averaged velocity $U = U^2h/Uh$, flow depth $H = (Uh)^2/U^2h)$, flow discharge $Q = Uh$, concentration $C = UCh/Uh$ and local densimetric Froude number $Fr$ (see [01-Computing-and-Plotting.ipynb](01-Computing-and-Plotting.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_averaged(ds, datapath):\n",
    "    '''\n",
    "    This function reads the raw binary fields from the disc and computes the\n",
    "    Layer-averaged (LA) quantities, as described above.\n",
    "    \n",
    "    Args:\n",
    "        ds: A base xarray.Dataset where LA variables are going to be stored.\n",
    "        datapath: Path to the folder containg the simulated data.\n",
    "    \n",
    "    Returns:\n",
    "        A xarray.Dataset with LA quantities\n",
    "    '''\n",
    "    # Tmp Initialization\n",
    "    fields = xr.Dataset()\n",
    "\n",
    "    fields['u'] = xr.DataArray(x3d_readfield_all_2d(\n",
    "        os.path.join(datapath, 'xy-plane', 'ux????'), ds.x.size, ds.y.size),\n",
    "                               dims=['x', 'y', 't'],\n",
    "                               coords=[ds.x, ds.y,\n",
    "                                       ds.t])\n",
    "    fields['c'] = xr.concat([\n",
    "        xr.DataArray(x3d_readfield_all_2d(\n",
    "            os.path.join(datapath, 'xy-plane', f'phi{n+1}????'), ds.x.size,\n",
    "            ds.y.size),\n",
    "                     dims=['x', 'y', 't'],\n",
    "                     coords=[ds.x, ds.y, ds.t]) for n in ds.n.to_index()\n",
    "    ], 'n')\n",
    "    #\n",
    "    fields['uc'] = fields['u'] * fields['c'].sum('n')\n",
    "    #\n",
    "    mask = fields.uc >= 0.005\n",
    "    #\n",
    "    ds['Uh'] = (fields.u).where(mask, 0.0).integrate('y')\n",
    "    ds['U2h'] = (fields.u**2.0).where(mask, 0.0).integrate('y')\n",
    "    ds['UCh'] = (fields.u * fields.c).where(mask, 0.0).integrate('y')\n",
    "    #\n",
    "    ds.Uh.attrs = {'name': 'Layer-averaged Uh', 'long_name': r'$Uh$'}\n",
    "    ds.U2h.attrs = {'name': 'Layer-averaged U2h', 'long_name': r'$U^2h$'}\n",
    "    ds.UCh.attrs = {'name': 'Layer-averaged UCh', 'long_name': r'$UCh$'}\n",
    "    #\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LA quantities\n",
    "\n",
    "The block bellow computes and writes to the disc a data set containing the layer-averaged quantities, in addition to spanwise-averaged bed shear velocity and spanwise-averaged deposition rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in tqdm(cases, desc='Case'):\n",
    "    path = \"D:/Simulacoes_Arquivadas/run3/incompact3d_plumes_edition/exp-\" + str(sim)\n",
    "    #\n",
    "    prm = read_prm_to_dict(path)\n",
    "    #\n",
    "    ds = init_dataset(prm)\n",
    "    #\n",
    "    ds = layer_averaged(ds, prm['datapath'])\n",
    "    #\n",
    "    ds['utau'] = xr.DataArray(\n",
    "        x3d_readfield_all_2d(os.path.join(prm['datapath'], 'xz-plane', 'utau*'),\n",
    "                             ds.x.size, ds.z.size),\n",
    "        dims=['x', 'z', 't'],\n",
    "        coords=[ds.x, ds.z, ds.t],\n",
    "    ).mean('z')\n",
    "    ds.utau.attrs = {'name': 'Bed shear velocity', 'long_name': r'$u_\\tau$'}\n",
    "    #\n",
    "    ds['dep'] = xr.concat([\n",
    "        xr.DataArray(x3d_readfield_all_2d(\n",
    "            os.path.join(prm['datapath'], 'xz-plane', f'dep{n+1}*'), ds.x.size,\n",
    "            ds.z.size),\n",
    "                     dims=['x', 'z', 't'],\n",
    "                     coords=[ds.x, ds.z, ds.t]).mean('z')\n",
    "        for n in ds.n.to_index()\n",
    "    ], 'n')\n",
    "    ds.dep.attrs = {'name': 'Deposition rate', 'long_name': r'$\\dot{D}$'}\n",
    "    # Cut to test section and save file\n",
    "    ds.sel(x=slice(prm['xlx_pi'], prm['xlx_pf'])).to_netcdf(f'LA-case-{sim}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xy-planes\n",
    "\n",
    "This block converts the raw binary containing the spanwise-averaged planes to NefCDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in tqdm(cases, desc='Case'):\n",
    "    path = os.path.normcase(\n",
    "        \"D:/Simulacoes_Arquivadas/run3/incompact3d_plumes_edition/exp-\"\n",
    "        + str(sim))\n",
    "    #\n",
    "    prm = read_prm_to_dict(path)\n",
    "    #\n",
    "    ds = init_dataset(prm)\n",
    "    #\n",
    "    for i, var in enumerate('ux uy uz'.split()):\n",
    "\n",
    "        ds[var] = xr.DataArray(x3d_readfield_all_2d(\n",
    "        os.path.join(path, 'data', 'xy-plane', f'{var}????'), ds.x.size, ds.y.size),\n",
    "                               dims=['x', 'y', 't'],\n",
    "                               coords=[ds.x, ds.y,ds.t],\n",
    "                               attrs={\n",
    "                                   'name': f\"{description.get(i,'')} Velocity\",\n",
    "                                   'long_name': fr\"$u_{i+1}$\"\n",
    "                               })\n",
    "    #\n",
    "    ds['phi'] = xr.concat([\n",
    "        xr.DataArray(x3d_readfield_all_2d(\n",
    "            os.path.join(path, 'data', 'xy-plane', f'phi{n+1}????'), ds.x.size,\n",
    "            ds.y.size),\n",
    "                     dims=['x', 'y', 't'],\n",
    "                     coords=[ds.x, ds.y, ds.t]) for n in ds.n.to_index()\n",
    "    ], 'n')\n",
    "    #\n",
    "    ds['phi'].attrs['name'] = 'Concentration Field'\n",
    "    ds['phi'].attrs['long_name'] = r'$\\varphi$'\n",
    "    # Cut to test section and save file\n",
    "    # Cut in time because of the size limitation at Zenodo\n",
    "    ds.sel(x=slice(prm['xlx_pi'], prm['xlx_pf']),t=slice(None,None,2)).to_netcdf(f'xy-planes-case-{sim}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xz-planes\n",
    "\n",
    "This block converts the raw binary containing the depth-averaged planes to NefCDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in tqdm(cases, desc='Case'):\n",
    "    path = os.path.normcase(\n",
    "        \"D:/Simulacoes_Arquivadas/run3/incompact3d_plumes_edition/exp-\"\n",
    "        + str(sim))\n",
    "    #\n",
    "    prm = read_prm_to_dict(path)\n",
    "    #\n",
    "    ds = init_dataset(prm)\n",
    "    #\n",
    "    for i, var in enumerate('ux uy uz'.split()):\n",
    "        ds[var] = xr.DataArray(x3d_readfield_all_2d(\n",
    "        os.path.join(path, 'data', 'xz-plane', f'{var}????'), ds.x.size, ds.z.size),\n",
    "                               dims=['x', 'z', 't'],\n",
    "                               coords=[ds.x, ds.z,ds.t],\n",
    "                               attrs={\n",
    "                                   'name': f\"{description.get(i,'')} Velocity\",\n",
    "                                   'long_name': fr\"$u_{i+1}$\"\n",
    "                               })\n",
    "    #\n",
    "    ds['phi'] = xr.concat([\n",
    "        xr.DataArray(x3d_readfield_all_2d(\n",
    "            os.path.join(path, 'data', 'xz-plane', f'phi{n+1}????'), ds.x.size,\n",
    "            ds.z.size),\n",
    "                     dims=['x', 'z', 't'],\n",
    "                     coords=[ds.x, ds.z, ds.t]) for n in ds.n.to_index()\n",
    "    ], 'n')\n",
    "    #\n",
    "    ds['phi'].attrs['name'] = 'Concentration Field'\n",
    "    ds['phi'].attrs['long_name'] = r'$\\varphi$'\n",
    "    # Cut to test section and save file\n",
    "    # Cut in time because of the size limitation at Zenodo\n",
    "    ds.sel(x=slice(prm['xlx_pi'], prm['xlx_pf']),t=slice(None,None,2)).to_netcdf(f'xz-planes-case-{sim}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D-Snapshots\n",
    "\n",
    "This block converts the raw binary containing the 3D fields to NefCDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.array([250,\n",
    "                  500,\n",
    "                  750,\n",
    "                  1000,\n",
    "                  1250,\n",
    "                  1500,\n",
    "                  1750,\n",
    "                  2000,\n",
    "                  3000,\n",
    "                  4000,\n",
    "                  5000,\n",
    "                  6000],\n",
    "                 dtype=myfloat)\n",
    "\n",
    "for sim in tqdm(cases, desc='Case'):\n",
    "    path = os.path.normcase(\n",
    "        \"D:/Simulacoes_Arquivadas/run3/incompact3d_plumes_edition/exp-\"\n",
    "        + str(sim))\n",
    "    #\n",
    "    prm = read_prm_to_dict(path)\n",
    "    #\n",
    "    ds = init_dataset(prm)\n",
    "    #\n",
    "    ds['t'] = times\n",
    "    ds.t.attrs = {'name': 'Time', 'long_name': r'$t$'}\n",
    "    #\n",
    "    itimes = np.array(times / prm['dt'] / prm['imodulo'], dtype=np.int32)\n",
    "    #\n",
    "    for i, var in enumerate('ux uy uz'.split()):\n",
    "        ds[var] = xr.DataArray(myfloat(0.),\n",
    "                               coords=[ds.x, ds.y, ds.z, ds.t],\n",
    "                               attrs={\n",
    "                                   'name': f\"{description.get(i,'')} Velocity\",\n",
    "                                   'long_name': fr\"$u_{i+1}$\"\n",
    "                               })\n",
    "        for k, t in enumerate(ds.t):\n",
    "            ds[var][dict(t=k)] += x3d_readfield_3d(\n",
    "                os.path.join(path, 'data', '3d-snapshot',\n",
    "                             var + str(itimes[k]).zfill(4)), ds.x.size,\n",
    "                ds.y.size, ds.z.size)\n",
    "    #\n",
    "    ds['phi'] = xr.DataArray(myfloat(0.),\n",
    "                               coords=[ds.x, ds.y, ds.z, ds.t, ds.n],\n",
    "                               attrs={\n",
    "                               'name': 'Concentration Field',\n",
    "                               'long_name': r'$\\varphi$'\n",
    "                           })\n",
    "    #\n",
    "    var = 'phi'\n",
    "    for k, t in enumerate(ds.t):\n",
    "        for n in ds.n.values:\n",
    "            ds[var][dict(t=k,n=n)] += x3d_readfield_3d(\n",
    "                os.path.join(path, 'data', '3d-snapshot',\n",
    "                             var + str(n+1) + str(itimes[k]).zfill(4)), ds.x.size,\n",
    "                ds.y.size, ds.z.size)\n",
    "    # Cut to test section, clear bellow channel's bed and save file\n",
    "    ds.where(ds.y < ds.ramp, 0.0).sel(x=slice(prm['xlx_pi'], prm['xlx_pf'])).to_netcdf(f'3d-case-{sim}.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
